{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полносвязная модель для датасета MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Входной размер: in_dim;\n",
    "#  Количество нейронов в первом слое нейронной сети n_hidden_1;\n",
    "#  Количество нейронов во втором слое нейронной сети n_hidden_2, out_dim\n",
    "#  Количество нейронов в третьем слое сети (вывод в)\n",
    "\n",
    "class simpleNet(nn.Module):\n",
    "    def __init__(self,in_dim,n_hidden_1,n_hidden_2,out_dim):\n",
    "        super(simpleNet,self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim,n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1,n_hidden_2)\n",
    "        self.layer3= nn.Linear(n_hidden_2,out_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        hidden_1_out = self.layer1(x)\n",
    "        hidden_2_out = self.layer2(hidden_1_out)\n",
    "        out = self.layer3(hidden_2_out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50,Train Loss:0.463890\n",
      "epoch: 100,Train Loss:0.388615\n",
      "epoch: 150,Train Loss:0.493248\n",
      "epoch: 200,Train Loss:0.481885\n",
      "epoch: 250,Train Loss:0.285333\n",
      "epoch: 300,Train Loss:0.508131\n",
      "epoch: 350,Train Loss:0.368897\n",
      "epoch: 400,Train Loss:0.285408\n",
      "epoch: 450,Train Loss:0.222345\n",
      "epoch: 500,Train Loss:0.255201\n",
      "epoch: 550,Train Loss:0.459309\n",
      "epoch: 600,Train Loss:0.600211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/fy4jnmhn3l72v47ky8bt9r9w0000gn/T/ipykernel_67098/1025919584.py:56: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  img = Variable(img,volatile=True)\n",
      "/var/folders/rw/fy4jnmhn3l72v47ky8bt9r9w0000gn/T/ipykernel_67098/1025919584.py:57: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label,volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.316099,Acc:0.908900\n"
     ]
    }
   ],
   "source": [
    "# гиперпараметры\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "data_tf = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize([0.5],[0.5])])\n",
    "train_dataset = datasets.MNIST(root='./data',train=True,transform=data_tf,download=True)\n",
    "test_dataset = datasets.MNIST(root='./data',train=False,transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "# Размер входного изображения - 28 * 28; два скрытых слоя - 300 и 100 соответственно; конечный размер вывода - 10\n",
    "model = simpleNet(28*28,300,100,10)  \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Перекрестная потеря энтропии\n",
    "optimizer = optim.Adagrad(model.parameters(),lr=learning_rate) # Функция оптимизации\n",
    "\n",
    "# Тренировочная модель\n",
    "epoch = 0\n",
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "    else:\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    print_loss = loss.data.item()\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch+=1\n",
    "    if epoch%50 == 0:\n",
    "        print(f'epoch: {epoch},Train Loss:{loss.data.item():.6f}')  \n",
    "\n",
    "#Model Evaluation\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "eval_acc = 0\n",
    "for data in test_loader:\n",
    "    img,label = data\n",
    "    img = img.view(img.size(0),-1)  \n",
    "    if torch.cuda.is_available():\n",
    "        img = Variable(img,volatile=True).cuda()\n",
    "        label = Variable(label,volatile=True).cuda()\n",
    "    else:\n",
    "        img = Variable(img,volatile=True)\n",
    "        label = Variable(label,volatile=True)\n",
    "    out = model(img)\n",
    "    loss = criterion(out,label)\n",
    "    eval_loss += loss.data.item() * label.size(0)\n",
    "    _,pred = torch.max(out,1)\n",
    "    num_correct = (pred==label).sum()\n",
    "    eval_acc += num_correct.data.item()\n",
    "print(f'Test Loss:{eval_loss/(len(test_dataset)):.6f},Acc:{eval_acc/(len(test_dataset)):.6f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сверточная модель для датасета MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 4, step 2000 / 15000, loss = 0.1087\n",
      "epoch 1 / 4, step 4000 / 15000, loss = 0.0003\n",
      "epoch 1 / 4, step 6000 / 15000, loss = 0.0018\n",
      "epoch 1 / 4, step 8000 / 15000, loss = 0.0124\n",
      "epoch 1 / 4, step 10000 / 15000, loss = 0.0002\n",
      "epoch 1 / 4, step 12000 / 15000, loss = 0.0038\n",
      "epoch 1 / 4, step 14000 / 15000, loss = 0.0071\n",
      "epoch 2 / 4, step 2000 / 15000, loss = 0.3147\n",
      "epoch 2 / 4, step 4000 / 15000, loss = 0.0258\n",
      "epoch 2 / 4, step 6000 / 15000, loss = 0.0009\n",
      "epoch 2 / 4, step 8000 / 15000, loss = 0.0002\n",
      "epoch 2 / 4, step 10000 / 15000, loss = 0.0545\n",
      "epoch 2 / 4, step 12000 / 15000, loss = 0.0011\n",
      "epoch 2 / 4, step 14000 / 15000, loss = 0.0169\n",
      "epoch 3 / 4, step 2000 / 15000, loss = 0.1524\n",
      "epoch 3 / 4, step 4000 / 15000, loss = 0.0026\n",
      "epoch 3 / 4, step 6000 / 15000, loss = 0.0005\n",
      "epoch 3 / 4, step 8000 / 15000, loss = 0.0122\n",
      "epoch 3 / 4, step 10000 / 15000, loss = 0.1437\n",
      "epoch 3 / 4, step 12000 / 15000, loss = 0.1464\n",
      "epoch 3 / 4, step 14000 / 15000, loss = 0.0044\n",
      "epoch 4 / 4, step 2000 / 15000, loss = 0.0006\n",
      "epoch 4 / 4, step 4000 / 15000, loss = 0.0000\n",
      "epoch 4 / 4, step 6000 / 15000, loss = 0.0011\n",
      "epoch 4 / 4, step 8000 / 15000, loss = 0.0012\n",
      "epoch 4 / 4, step 10000 / 15000, loss = 0.0049\n",
      "epoch 4 / 4, step 12000 / 15000, loss = 0.0001\n",
      "epoch 4 / 4, step 14000 / 15000, loss = 0.0001\n",
      "accuracy = 98.62 %\n",
      "\n",
      "accuracy of 0: 99.59 %\n",
      "accuracy of 1: 99.30 %\n",
      "accuracy of 2: 99.52 %\n",
      "accuracy of 3: 99.21 %\n",
      "accuracy of 4: 99.39 %\n",
      "accuracy of 5: 98.77 %\n",
      "accuracy of 6: 98.02 %\n",
      "accuracy of 7: 98.54 %\n",
      "accuracy of 8: 97.64 %\n",
      "accuracy of 9: 96.13 %\n"
     ]
    }
   ],
   "source": [
    "# гиперпараметры\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "n_classes = len(classes)\n",
    "\n",
    "\n",
    "# nn\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "\n",
    "# функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# train\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(n_classes)]\n",
    "    n_class_samples = [0 for i in range(n_classes)]\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # max returns (value, index)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predictions[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc} %\\n')\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'accuracy of {classes[i]}: {acc:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "339719716788efbebc21d3c87ba48596bcb1d0c53d0dbb67e99e06575199d88a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
