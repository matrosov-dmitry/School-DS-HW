{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJfkstKpqsXp"
      },
      "source": [
        "### ML1_1: \n",
        "https://www.hackerrank.com/challenges/capturing-non-capturing-groups/problem?isFullScreen=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "Regex_Pattern = r'(?:o[kK]){3}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML1_2: \n",
        "https://www.hackerrank.com/challenges/branch-reset-groups/problem?isFullScreen=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "Regex_Pattern = '/^\\d{2}(-{3}|:|.|-)(\\d{2}\\1){2}\\d{2}$/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML1_3: \n",
        "https://www.hackerrank.com/challenges/detect-html-links/problem?isFullScreen=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML1_4\n",
        "Реализовать stemming, lemmatization & BoW на следующем датасете: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK (Russian Toxic-abuse comments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /Users/matdiv/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /Users/matdiv/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import  SnowballStemmer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                          Собаке - собачья смерть\\n    1.0\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('./data/labeled.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14412, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# удаление пунктуации\n",
        "data['comment'] = data['comment'].str.replace('[^\\w\\s]','', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['comment'] = data['comment'].str.replace('[\\n]','', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  приведение слов к нижнему регистру\n",
        "\n",
        "data['comment'] = data['comment'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# удаление стоп-слов\n",
        "stop = stopwords.words('russian')\n",
        "\n",
        "data['comment'] = data['comment'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>верблюдовто дебилы бл</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>собаке собачья смерть</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>страницу обнови дебил это оскорбление доказанн...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>убедил 6страничный пдф скрипалей отравила росс...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  toxic\n",
              "0                              верблюдовто дебилы бл    1.0\n",
              "1  хохлы это отдушина затюканого россиянина мол в...    1.0\n",
              "2                              собаке собачья смерть    1.0\n",
              "3  страницу обнови дебил это оскорбление доказанн...    1.0\n",
              "4  убедил 6страничный пдф скрипалей отравила росс...    1.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# стемминг\n",
        "\n",
        "stem = SnowballStemmer(\"russian\")\n",
        "\n",
        "data['comment_stem'] = data['comment'].apply(lambda x: \" \".join([stem.stem(word) for word in x.split()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# лемматизация\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "data['comment_lemm'] = data['comment'].apply(lambda x: \" \".join([morph.normal_forms(word)[0] for word in x.split()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "      <th>comment_stem</th>\n",
              "      <th>comment_lemm</th>\n",
              "      <th>comment_lemm_stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>верблюдовто дебилы бл</td>\n",
              "      <td>1.0</td>\n",
              "      <td>верблюдовт дебил бл</td>\n",
              "      <td>верблюдовто дебил бл</td>\n",
              "      <td>верблюдовт дебил бл</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>хохл эт отдушин затюкан россиянин мол вон хохл...</td>\n",
              "      <td>хохол это отдушина затюканый россиянин мол вон...</td>\n",
              "      <td>хохлый эт отдушина затюкать россиянин мол вон ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>собаке собачья смерть</td>\n",
              "      <td>1.0</td>\n",
              "      <td>собак собач смерт</td>\n",
              "      <td>собака собачий смерть</td>\n",
              "      <td>собака собач смерт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>страницу обнови дебил это оскорбление доказанн...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>страниц обнов деб эт оскорблен доказа факт нед...</td>\n",
              "      <td>страница обновить дебил это оскорбление доказа...</td>\n",
              "      <td>страница обнова деб эт оскорбить доказ факт не...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>убедил 6страничный пдф скрипалей отравила росс...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>убед 6страничн пдф скрипал отрав росс анализир...</td>\n",
              "      <td>убедить 6страничный пдф скрипаль отравить росс...</td>\n",
              "      <td>убеда 6страничн пдф скрипасть отрава росс анал...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14407</th>\n",
              "      <td>вонючий совковый скот прибежал ноет сторонник ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>вонюч совков скот прибежа ноет сторонник демок...</td>\n",
              "      <td>вонючий совковый скот прибежать ныть сторонник...</td>\n",
              "      <td>вонючий совковый скот прибежа ныть сторонник д...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14408</th>\n",
              "      <td>кого любить гоблина тупорылого чтоли какуюнибу...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ког люб гоблин тупорыл чтол какуюнибуд продажн...</td>\n",
              "      <td>кто любить гоблин тупорылый чтоль какуюнибудь ...</td>\n",
              "      <td>ког люба гоблин тупорылый чтол какуюнибуд прод...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14409</th>\n",
              "      <td>посмотрел утомленных солнцем 2 оказалось это х...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>посмотрел утомлен солнц 2 оказа эт хорош фильм...</td>\n",
              "      <td>посмотреть утомлённый солнце 2 оказаться это х...</td>\n",
              "      <td>посмотреть утомлённый солнце 2 оказ эт хороший...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14410</th>\n",
              "      <td>крымотред нарушает правила раздела тк нем обсу...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>крымотред наруша прав раздел тк нем обсужден п...</td>\n",
              "      <td>крымотред нарушать правило раздел тк немой обс...</td>\n",
              "      <td>крымотред нарушить право раздел тк немой обсуд...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14411</th>\n",
              "      <td>сих пор пересматриваю видео орамбо кстати свое...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>сих пор пересматрива виде орамб кстат сво кана...</td>\n",
              "      <td>сей пора пересматривать видео орамбо кстати св...</td>\n",
              "      <td>сей пора пересматрива вид орамб кстат сво кана...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14412 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 comment  toxic  \\\n",
              "0                                  верблюдовто дебилы бл    1.0   \n",
              "1      хохлы это отдушина затюканого россиянина мол в...    1.0   \n",
              "2                                  собаке собачья смерть    1.0   \n",
              "3      страницу обнови дебил это оскорбление доказанн...    1.0   \n",
              "4      убедил 6страничный пдф скрипалей отравила росс...    1.0   \n",
              "...                                                  ...    ...   \n",
              "14407  вонючий совковый скот прибежал ноет сторонник ...    1.0   \n",
              "14408  кого любить гоблина тупорылого чтоли какуюнибу...    1.0   \n",
              "14409  посмотрел утомленных солнцем 2 оказалось это х...    0.0   \n",
              "14410  крымотред нарушает правила раздела тк нем обсу...    1.0   \n",
              "14411  сих пор пересматриваю видео орамбо кстати свое...    0.0   \n",
              "\n",
              "                                            comment_stem  \\\n",
              "0                                    верблюдовт дебил бл   \n",
              "1      хохл эт отдушин затюкан россиянин мол вон хохл...   \n",
              "2                                      собак собач смерт   \n",
              "3      страниц обнов деб эт оскорблен доказа факт нед...   \n",
              "4      убед 6страничн пдф скрипал отрав росс анализир...   \n",
              "...                                                  ...   \n",
              "14407  вонюч совков скот прибежа ноет сторонник демок...   \n",
              "14408  ког люб гоблин тупорыл чтол какуюнибуд продажн...   \n",
              "14409  посмотрел утомлен солнц 2 оказа эт хорош фильм...   \n",
              "14410  крымотред наруша прав раздел тк нем обсужден п...   \n",
              "14411  сих пор пересматрива виде орамб кстат сво кана...   \n",
              "\n",
              "                                            comment_lemm  \\\n",
              "0                                   верблюдовто дебил бл   \n",
              "1      хохол это отдушина затюканый россиянин мол вон...   \n",
              "2                                  собака собачий смерть   \n",
              "3      страница обновить дебил это оскорбление доказа...   \n",
              "4      убедить 6страничный пдф скрипаль отравить росс...   \n",
              "...                                                  ...   \n",
              "14407  вонючий совковый скот прибежать ныть сторонник...   \n",
              "14408  кто любить гоблин тупорылый чтоль какуюнибудь ...   \n",
              "14409  посмотреть утомлённый солнце 2 оказаться это х...   \n",
              "14410  крымотред нарушать правило раздел тк немой обс...   \n",
              "14411  сей пора пересматривать видео орамбо кстати св...   \n",
              "\n",
              "                                       comment_lemm_stem  \n",
              "0                                    верблюдовт дебил бл  \n",
              "1      хохлый эт отдушина затюкать россиянин мол вон ...  \n",
              "2                                     собака собач смерт  \n",
              "3      страница обнова деб эт оскорбить доказ факт не...  \n",
              "4      убеда 6страничн пдф скрипасть отрава росс анал...  \n",
              "...                                                  ...  \n",
              "14407  вонючий совковый скот прибежа ныть сторонник д...  \n",
              "14408  ког люба гоблин тупорылый чтол какуюнибуд прод...  \n",
              "14409  посмотреть утомлённый солнце 2 оказ эт хороший...  \n",
              "14410  крымотред нарушить право раздел тк немой обсуд...  \n",
              "14411  сей пора пересматрива вид орамб кстат сво кана...  \n",
              "\n",
              "[14412 rows x 5 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['comment_lemm_stem'] = data['comment_stem'].apply(lambda x: \" \".join([morph.normal_forms(word)[0] for word in x.split()]))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "bow = vectorizer.fit_transform(data['comment_lemm_stem'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 5672)\t1\n",
            "  (0, 8532)\t1\n",
            "  (0, 4681)\t1\n",
            "  (1, 32533)\t3\n",
            "  (1, 34042)\t1\n",
            "  (1, 19672)\t1\n",
            "  (1, 11134)\t1\n",
            "  (1, 26427)\t1\n",
            "  (1, 16135)\t1\n",
            "  (1, 6376)\t1\n",
            "  (1, 32654)\t1\n",
            "  (1, 12944)\t1\n",
            "  (1, 23814)\t1\n",
            "  (2, 28099)\t1\n",
            "  (2, 28102)\t1\n",
            "  (2, 27963)\t1\n",
            "  (3, 34042)\t2\n",
            "  (3, 29124)\t1\n",
            "  (3, 18571)\t1\n",
            "  (3, 8525)\t1\n",
            "  (3, 19472)\t1\n",
            "  (3, 9273)\t1\n",
            "  (3, 31606)\t1\n",
            "  (3, 17421)\t1\n",
            "  (3, 16056)\t1\n",
            "  :\t:\n",
            "  (14410, 17307)\t1\n",
            "  (14410, 23647)\t1\n",
            "  (14411, 29609)\t1\n",
            "  (14411, 14146)\t1\n",
            "  (14411, 27083)\t1\n",
            "  (14411, 22834)\t1\n",
            "  (14411, 5866)\t1\n",
            "  (14411, 12733)\t1\n",
            "  (14411, 13152)\t1\n",
            "  (14411, 23257)\t1\n",
            "  (14411, 13535)\t1\n",
            "  (14411, 5693)\t1\n",
            "  (14411, 21358)\t1\n",
            "  (14411, 12508)\t1\n",
            "  (14411, 27228)\t1\n",
            "  (14411, 27004)\t1\n",
            "  (14411, 16689)\t1\n",
            "  (14411, 25964)\t1\n",
            "  (14411, 23269)\t1\n",
            "  (14411, 32558)\t1\n",
            "  (14411, 7850)\t1\n",
            "  (14411, 20925)\t1\n",
            "  (14411, 19359)\t1\n",
            "  (14411, 33647)\t1\n",
            "  (14411, 32593)\t1\n"
          ]
        }
      ],
      "source": [
        "print(bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Задание 6: \n",
        "https://www.hackerrank.com/challenges/matching-specific-string/problem?isFullScreen=true \n",
        "\n",
        "Regex_Pattern = r\"hackerrank\"\n",
        "\n",
        "### Задание 7: \n",
        "https://www.hackerrank.com/challenges/matching-whitespace-non-whitespace-character/problem?isFullScreen=true\n",
        "\n",
        "Regex_Pattern = r\"(\\S\\S\\s)(\\S\\S\\s)(\\S\\S)\"\n",
        "\n",
        "### Задание 8: \n",
        "https://www.hackerrank.com/challenges/matching-start-end/problem?isFullScreen=true\n",
        "\n",
        "Regex_Pattern = r\"^[0-9]{1}[0-9A-Za-z]{2,4}\\.$\"\n",
        "\n",
        "### Задание 9: \n",
        "https://www.hackerrank.com/challenges/matching-word-boundaries/problem?isFullScreen=true\n",
        "\n",
        "Regex_Pattern = r'\\b[a,e,i,o,u,A,E,I,O,U][A-Za-z]*\\b'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP1_homework",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
